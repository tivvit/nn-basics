{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Multilayer_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.79900000e+01,   1.03800000e+01,   1.22800000e+02,\n",
       "         1.00100000e+03,   1.18400000e-01,   2.77600000e-01,\n",
       "         3.00100000e-01,   1.47100000e-01,   2.41900000e-01,\n",
       "         7.87100000e-02,   1.09500000e+00,   9.05300000e-01,\n",
       "         8.58900000e+00,   1.53400000e+02,   6.39900000e-03,\n",
       "         4.90400000e-02,   5.37300000e-02,   1.58700000e-02,\n",
       "         3.00300000e-02,   6.19300000e-03,   2.53800000e+01,\n",
       "         1.73300000e+01,   1.84600000e+02,   2.01900000e+03,\n",
       "         1.62200000e-01,   6.65600000e-01,   7.11900000e-01,\n",
       "         2.65400000e-01,   4.60100000e-01,   1.18900000e-01])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.target\n",
    "X = data.data\n",
    "features_num = len(data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heavyside(n):\n",
    "    return tf.where(tf.greater(n, 0), 1., 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'const' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-fff26f69441e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#.minimize(cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtran_op1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'const' is not defined"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random_normal([1, features_num])) #, tf.float32)\n",
    "b = tf.Variable(tf.zeros([1])) #, tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "init_op = tf.global_variables_initializer()\n",
    "perceptron = tf.add(tf.reduce_sum(tf.multiply(w, x)), b)\n",
    "predict = heavyside(perceptron[0])\n",
    "\n",
    "cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=[predict]))\n",
    "#updates = tf.train.GradientDescentOptimizer(0.1)\n",
    "\n",
    "#.minimize(cost)\n",
    "grads = tf.gradients(const, w)\n",
    "tran_op1 = cost.apply_gradients(zip(grads1, var_list1))\n",
    "                \n",
    "with tf.Session() as sess:\n",
    "    # Run the init operation.\n",
    "    sess.run(init_op)\n",
    "    epochs = 20\n",
    "    lr = 0.8\n",
    "    X = X[:40]\n",
    "    for e in range(epochs):\n",
    "        sq_err = 0\n",
    "        print(len(X))\n",
    "        for i in range(len(X)):\n",
    "            res = sess.run(updates, feed_dict={\n",
    "                x: X[i],\n",
    "                y: Y[i],\n",
    "            })[0]\n",
    "            #print(res)\n",
    "            #print(sess.run(w))\n",
    "            \n",
    "            #pred = heavyside(res) \n",
    "            \n",
    "            #print(pred)\n",
    "            #print(y[i], pred)\n",
    "            \n",
    "            #err = Y[i] - pred\n",
    "            #sq_err += err ** 2\n",
    "            #print(err, err * lr, err * lr * X[i])\n",
    "            #grad = err * lr * X[i]\n",
    "            #w += grad\n",
    "            #print(b)\n",
    "            #b += err * lr\n",
    "            #sess.run([w, b])\n",
    "            #print(b)\n",
    "            #print(err)\n",
    "            if i % 10 == 0:\n",
    "                print(i / 10)\n",
    "        print(\"Epoch {} mse: {}\".format(e, sq_err / len(X)))\n",
    "        print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
